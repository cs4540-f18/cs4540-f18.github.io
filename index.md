# Course Info

**Professor:** Jacob Abernethy<br>
**TAs:** Benjamin Bray and Naveen Kodali<br>
**Location:** Tu/Th 3-4:15pm in Klaus 2443

This is an advanced course on algorithms. That is quite a broad topic, and in particular this semester’s course will focus heavily on algorithms for machine learning. We will be especially interested in diving into the following topics: Numerical Analysis, Convex Optimization, and Probability and Statistics. While students should have a strong back background in core algorithmic concepts, linear algebra, and probability, we will review many of these topics early in the course. Students will be required to write code in Python, and we will present much of the material in the course using the Jupyter Notebook (the use of such notebooks will be reviewed in Lecture 2).

## Hands-on Format

Most courses are taught with the following structure: Students learn about material in class through lecture, and then they practice problem solving on their own by doing homework. In this course we will do the opposite! Students will be required to read material before each class period, and then arrive in class ready to dive into problem-solving.  Lecture notes for each day will be posted online at least one week prior to each lecture.

Why do it like this? The lecture format is an outdated way to teach mathematical material, especially for topics such as algorithms and machine learning where it is so easy to play with code and implement ideas. The lecture format also limits the professor’s ability to interact directly with students.

Each class period will have the following structure:

* *(0mins)* Students arrive and organize themselves by sitting with their group
* *(5mins)* Students take a very short and simple quiz on assigned reading material
* *(55mins)* Problem time! Instructor presents a sequence of problems, and students are given 5-10 minutes per problem to try to solve each one with their group. Instructors will move around the classroom to engage with students and answer questions.
* *(15mins)* Class wraps with a brief description of the forthcoming material for next period, in a “mini lecture”

## Grading

The course grades will be determined as follows.  Note that the in-class quizzes will be graded generously, and 50% of the credit will be given simply for showing up and answering the questions.

* Homeworks (35%)
* Attendance + Quizzes (15%)
* Midterm Exam (20%)
* Final Exam (30%)

## Reading

Readings will be assigned for you to complete *before each lecture*.  All required reading will either be linked to here or posted to canvas.  You are not required to purchase a textbook for this course, but you may find the following books helpful.

* Boyd & Vandengerbhe, *Convex Optimization* ([Free PDF](https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf))
* Trefethen & Bau, *Numerical Linear Algebra*

## Assignments

TODO

# Schedule

(Tu 8/21/18) **Lecture #1**:  Introduction & Perceptron

* CMU 15-859(B), Lecture #4, [The Perceptron Algorithm](https://www.cs.cmu.edu/~avrim/ML10/lect0125.pdf) by Avrim Blum
* Raul Rojas, Neural Networks:  A Systematic Introduction
  * [Ch 4:  Perceptron Learning](https://page.mi.fu-berlin.de/rojas/neural/chapter/K4.pdf)
  * [Ch 5:  Unsupervised Learning and Clustering Algorithms](https://page.mi.fu-berlin.de/rojas/neural/chapter/K5.pdf)
  
(Th 8/23/18) **Lecture #2**:  Review of Linear Algebra & Intro to Numpy

Required Reading (before class!)
* [Notebook]  CS 4540:  Python Basics
Additional Resources
* MIT OCW 18.06 Linear Algebra Lecture Videos

	
(Tu 8/28/18) **Lecture #3**:  Review of Calculus & Intro to Optimization

Required Reading
* Boyd & Vandenberghe, [Convex Optimization](https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf)
	* §2.1 Affine and Convex Sets
	* §2.2 Important Examples (of Affine and Convex Sets)
	* §3.1 Basic Properties and Examples (of Convex Functions)

Additional Resources
* Stanford EE364a, Lecture #2:  Convex Sets ([Slides](http://web.stanford.edu/class/ee364a/lectures/sets.pdf), [Video](https://www.youtube.com/watch?v=P3W_wFZ2kUo))
* Stanford EE364a, Lecture #3:  Convex Functions ([Slides](http://web.stanford.edu/class/ee364a/lectures/functions.pdf), [Video](https://www.youtube.com/watch?v=kcOodzDGV4c))

(Th 8/30/18) **Lecture #4**:  Convexity & Optimization

Required Reading
* Boyd & Vandenberghe, [Convex Optimization](https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf)
	* §2.5 Separating & Supporting Hyperplanes

Additional Resources
* Boyd & Vandenberghe, [Convex Optimization](https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf)
	* §2.3 Operations that Preserve Convex Sets
	* §3.2 Operations that Preserve Convex Functions

(Tu 9/4/18) **Lecture #5**:  Linear Programming

* Stanford CS261 Lecture Notes by Tim Roughgarden
  * [Lecture 7: Linear Programming: Introduction and Applications](http://theory.stanford.edu/~tim/w16/l/l7.pdf)
  * [Lecture 8: Linear Programming Duality (Part 1)](http://theory.stanford.edu/~tim/w16/l/l8.pdf)
  * [Lecture 9: Linear Programming Duality (Part 2)](http://theory.stanford.edu/~tim/w16/l/l9.pdf)
